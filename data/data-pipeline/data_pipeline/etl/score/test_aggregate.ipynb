{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Users/hayleeoyler/opt/anaconda3/envs/justice40-env/lib/python3.10/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Users/hayleeoyler/opt/anaconda3/envs/justice40-env/lib/python3.10/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_buckets_from_tracts(\n",
    "    initial_state_tracts: gpd.GeoDataFrame,\n",
    "    geoid_field_name: str,\n",
    "    target_score_field: str,\n",
    "    high_low_zoom_threshold: int,\n",
    "    number_of_buckets: int,\n",
    "    homogeneity_threshold: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Groups geographic tracts into buckets based on their scores.\n",
    "\n",
    "    Args:\n",
    "        initial_state_tracts (gpd.GeoDataFrame): GeoDataFrame containing the tracts.\n",
    "        geoid_field_name (str): The name of the GEOID field in the GeoDataFrame.\n",
    "        target_score_field (str): The name of the score field to use for bucketing.\n",
    "        high_low_zoom_threshold (int): Minimum number of tracts required to avoid aggregation.\n",
    "        number_of_buckets (int): Initial number of buckets to divide the tracts into.\n",
    "        homogeneity_threshold (int): Threshold for adjusting bucket sizes for homogeneity.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - state_tracts (gpd.GeoDataFrame): Tracts grouped into buckets.\n",
    "            - high_zoom_tracts (gpd.GeoDataFrame): Tracts kept at high zoom levels.\n",
    "    \"\"\"\n",
    "    # Step 1: Identify states with fewer tracts than the threshold\n",
    "    highzoom_state_tracts = initial_state_tracts.reset_index()\n",
    "    highzoom_state_tracts[\"state\"] = highzoom_state_tracts[geoid_field_name].str[:2]\n",
    "    keep_high_zoom = highzoom_state_tracts.groupby(\"state\")[geoid_field_name].transform(\n",
    "        lambda x: x.count() <= high_low_zoom_threshold\n",
    "    )\n",
    "\n",
    "    # Ensure some tracts are kept at high zoom\n",
    "    assert keep_high_zoom.sum() != initial_state_tracts.shape[0], \\\n",
    "        \"Error: Cutoff is too high, nothing is aggregated\"\n",
    "    assert keep_high_zoom.sum() > 1, \"Error: Nothing is kept at high zoom\"\n",
    "\n",
    "    # Step 2: Separate tracts for high zoom and those to be bucketed\n",
    "    state_tracts = initial_state_tracts[~keep_high_zoom].copy()\n",
    "    state_tracts[f\"{target_score_field}_bucket\"] = np.arange(len(state_tracts))\n",
    "\n",
    "    # Step 3: Sort tracts by score and calculate bucket size\n",
    "    state_tracts = state_tracts.sort_values(target_score_field, ascending=True)\n",
    "    score_bucket = []\n",
    "    bucket_size = math.ceil(len(state_tracts.index) / number_of_buckets)\n",
    "\n",
    "    # Step 4: Adjust bucket size for homogeneity\n",
    "    while state_tracts[target_score_field].sum() % bucket_size > homogeneity_threshold:\n",
    "        number_of_buckets += 1\n",
    "        bucket_size = math.ceil(len(state_tracts.index) / number_of_buckets)\n",
    "\n",
    "    logger.debug(f\"The number of buckets has increased to {number_of_buckets}\")\n",
    "\n",
    "    # Step 5: Assign tracts to buckets\n",
    "    for i in range(len(state_tracts.index)):\n",
    "        score_bucket.append(math.floor(i / bucket_size))\n",
    "    state_tracts[f\"{target_score_field}_bucket\"] = score_bucket\n",
    "\n",
    "    # Step 6: Return bucketed tracts and high zoom tracts\n",
    "    return state_tracts, initial_state_tracts[keep_high_zoom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Example input data\n",
    "initial_state_tracts = gpd.read_file(\"path_to_your_geojson_or_shapefile.geojson\")\n",
    "\n",
    "# Parameters\n",
    "geoid_field_name = \"GEOID10\"\n",
    "target_score_field = \"SCORE\"\n",
    "high_low_zoom_threshold = 150\n",
    "number_of_buckets = 10\n",
    "homogeneity_threshold = 200\n",
    "\n",
    "# Call the function\n",
    "bucketed_tracts, high_zoom_tracts = create_buckets_from_tracts(\n",
    "    initial_state_tracts,\n",
    "    geoid_field_name,\n",
    "    target_score_field,\n",
    "    high_low_zoom_threshold,\n",
    "    number_of_buckets,\n",
    "    homogeneity_threshold\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(\"Bucketed Tracts:\")\n",
    "print(bucketed_tracts.head())\n",
    "\n",
    "print(\"High Zoom Tracts:\")\n",
    "print(high_zoom_tracts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _aggregate_buckets(\n",
    "        self, state_tracts: gpd.GeoDataFrame, agg_func: str\n",
    "    ) -> gpd.GeoDataFrame:\n",
    "        keep_cols = [\n",
    "            self.TARGET_SCORE_RENAME_TO,\n",
    "            f\"{self.TARGET_SCORE_RENAME_TO}_bucket\",\n",
    "            self.GEOMETRY_FIELD_NAME,\n",
    "        ]\n",
    "\n",
    "        #  We dissolve all other tracts by their score bucket\n",
    "        state_dissolve = state_tracts[keep_cols].dissolve(\n",
    "            by=f\"{self.TARGET_SCORE_RENAME_TO}_bucket\", aggfunc=agg_func\n",
    "        )\n",
    "        return state_dissolve\n",
    "\n",
    "def _breakup_multipolygons(\n",
    "    self, state_bucketed_df: gpd.GeoDataFrame, num_buckets: int\n",
    ") -> gpd.GeoDataFrame:\n",
    "\n",
    "    compressed = []\n",
    "    for i in range(num_buckets):\n",
    "        for j in range(\n",
    "            len(state_bucketed_df[self.GEOMETRY_FIELD_NAME][i].geoms)\n",
    "        ):\n",
    "            compressed.append(\n",
    "                [\n",
    "                    state_bucketed_df[self.TARGET_SCORE_RENAME_TO][i],\n",
    "                    state_bucketed_df[self.GEOMETRY_FIELD_NAME][i].geoms[j],\n",
    "                ]\n",
    "            )\n",
    "    return compressed\n",
    "\n",
    "def _join_high_and_low_zoom_frames(\n",
    "    self, compressed: list, keep_high_zoom_df: gpd.GeoDataFrame\n",
    ") -> gpd.GeoDataFrame:\n",
    "    keep_columns = [\n",
    "        self.TARGET_SCORE_RENAME_TO,\n",
    "        self.GEOMETRY_FIELD_NAME,\n",
    "    ]\n",
    "    compressed_geodf = gpd.GeoDataFrame(\n",
    "        compressed,\n",
    "        columns=keep_columns,\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    return pd.concat([compressed_geodf, keep_high_zoom_df[keep_columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakup_multipolygons(\n",
    "    state_bucketed_df: gpd.GeoDataFrame,\n",
    "    target_score_field: str,\n",
    "    geometry_field_name: str,\n",
    "    num_buckets: int\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Breaks up multipolygon geometries into individual polygons.\n",
    "\n",
    "    Args:\n",
    "        state_bucketed_df (gpd.GeoDataFrame): GeoDataFrame containing bucketed geometries.\n",
    "        target_score_field (str): The name of the score field.\n",
    "        geometry_field_name (str): The name of the geometry field.\n",
    "        num_buckets (int): Number of buckets.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of individual polygons with their associated scores.\n",
    "    \"\"\"\n",
    "    compressed = []\n",
    "    for i in range(num_buckets):\n",
    "        for j in range(len(state_bucketed_df[geometry_field_name][i].geoms)):\n",
    "            compressed.append(\n",
    "                [\n",
    "                    state_bucketed_df[target_score_field][i],\n",
    "                    state_bucketed_df[geometry_field_name][i].geoms[j],\n",
    "                ]\n",
    "            )\n",
    "    return compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def join_high_and_low_zoom_frames(\n",
    "    compressed: list,\n",
    "    keep_high_zoom_df: gpd.GeoDataFrame,\n",
    "    target_score_field: str,\n",
    "    geometry_field_name: str\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Combines high-zoom tracts with bucketed low-zoom tracts.\n",
    "\n",
    "    Args:\n",
    "        compressed (list): List of individual polygons with their scores.\n",
    "        keep_high_zoom_df (gpd.GeoDataFrame): GeoDataFrame of high-zoom tracts.\n",
    "        target_score_field (str): The name of the score field.\n",
    "        geometry_field_name (str): The name of the geometry field.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Combined GeoDataFrame.\n",
    "    \"\"\"\n",
    "    keep_columns = [\n",
    "        target_score_field,\n",
    "        geometry_field_name,\n",
    "    ]\n",
    "    compressed_geodf = gpd.GeoDataFrame(\n",
    "        compressed,\n",
    "        columns=keep_columns,\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    return pd.concat([compressed_geodf, keep_high_zoom_df[keep_columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the standalone functions\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load your GeoDataFrame\n",
    "state_tracts = gpd.read_file(\"path_to_your_geojson_or_shapefile.geojson\")\n",
    "\n",
    "# Parameters\n",
    "target_score_field = \"SCORE\"\n",
    "geometry_field_name = \"geometry\"\n",
    "agg_func = \"mean\"\n",
    "num_buckets = 10\n",
    "\n",
    "# Aggregate buckets\n",
    "aggregated = aggregate_buckets(state_tracts, target_score_field, geometry_field_name, agg_func)\n",
    "\n",
    "# Break up multipolygons\n",
    "compressed = breakup_multipolygons(aggregated, target_score_field, geometry_field_name, num_buckets)\n",
    "\n",
    "# Combine high-zoom and low-zoom frames\n",
    "keep_high_zoom_df = gpd.read_file(\"path_to_high_zoom_geojson.geojson\")\n",
    "combined = join_high_and_low_zoom_frames(compressed, keep_high_zoom_df, target_score_field, geometry_field_name)\n",
    "\n",
    "# Save the result\n",
    "combined.to_file(\"path_to_output.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "justice40-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
